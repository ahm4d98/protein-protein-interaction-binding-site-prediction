{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:33:19.145715Z",
     "start_time": "2021-09-01T05:33:19.134745Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features of each protein is located in 3 different sources that must be joined together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:33:35.853285Z",
     "start_time": "2021-09-01T05:33:34.479724Z"
    }
   },
   "outputs": [],
   "source": [
    "physical_features_directory = os.listdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\Ligand+Receptor\")\n",
    "os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\Ligand+Receptor\")\n",
    "physical_features=[]\n",
    "physicalname=[]\n",
    "for file in range(0,len(physical_features_directory)) :\n",
    "    os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\Ligand+Receptor\")\n",
    "    physicalname.append(physical_features_directory[file])\n",
    "    dfpsaia=pd.read_csv(physical_features_directory[file])\n",
    "   # print(dfpsaia)\n",
    "    physical_features.append(dfpsaia)\n",
    "print(len(physical_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:33:49.869547Z",
     "start_time": "2021-09-01T05:33:48.571020Z"
    }
   },
   "outputs": [],
   "source": [
    "chemical_features_directory = os.listdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\chemical features\")\n",
    "os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\chemical features\")\n",
    "chemicalname=[]\n",
    "chemical_features=[]\n",
    "for file in range(0,len(chemical_features_directory)) :\n",
    "    os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\chemical features\")\n",
    "    chemicalname.append(chemical_features_directory[file])\n",
    "    chemical=pd.read_csv(chemical_features_directory[file])\n",
    "    chemical=chemical.drop(['Unnamed: 0'],axis=1)\n",
    "    #print(chemical)\n",
    "    chemical_features.append(chemical)\n",
    "print(len(chemical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:34:07.614183Z",
     "start_time": "2021-09-01T05:34:05.676350Z"
    }
   },
   "outputs": [],
   "source": [
    "pssm_directory = os.listdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\PSSM\")\n",
    "os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\PSSM\")\n",
    "pssm=[]\n",
    "for file in range(0,len(pssm_directory)) :\n",
    "    os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\PSSM\")\n",
    "    pssmfile=pd.read_csv(chemical_features_directory[file])\n",
    "    pssmfile=pssmfile.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 1', 'Unnamed: 42','Unnamed: 43'],axis=1)\n",
    "    \n",
    "    print(pssmfile)\n",
    "    pssm.append(pssmfile)\n",
    "print(len(pssm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging protein features from each directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:34:18.820516Z",
     "start_time": "2021-09-01T05:34:18.807569Z"
    }
   },
   "outputs": [],
   "source": [
    "def mergeallfeatures(physical_features,chemical_features,pssm):\n",
    "    all_features=[]\n",
    "    letterabbreviation= {'CYS': 'C', 'ASP': 'D', 'GLN': 'Q', 'ILE': 'I',\n",
    "                     'ALA': 'A', 'TYR': 'Y', 'TRP': 'W', 'HIS': 'H',\n",
    "                     'LEU': 'L', 'ARG': 'R', 'VAL': 'V', 'GLU': 'E',\n",
    "                     'PHE': 'F', 'GLY': 'G', 'MET': 'M', 'ASN': 'N',\n",
    "                     'PRO': 'P', 'SER': 'S', 'LYS': 'K', 'THR': 'T',\n",
    "                     # extended set of amino acids:\n",
    "                     'MSE': 'M', 'CSE': 'U', 'LNT': 'X', 'GLH': 'E',\n",
    "                     'HID': 'H', 'HIE': 'H', 'HIP': 'H', 'HYP': 'P'\n",
    "                    }\n",
    "    for i in range(len(pssm)):\n",
    "        f=pd.merge(physical_features[i],chemical_features[i],right_index=True,left_index=True)\n",
    "        features=pd.merge(f,pssm[i],right_index=True,left_index=True)\n",
    "        #removing unnecessay columns\n",
    "        features=features.drop(['ch total ASA|', 'ch b-bone ASA|', 'ch s-chain ASA|','ch polar ASA|','ch n-polar ASA|'],axis=1)\n",
    "        letters = list(features['res name|'])\n",
    "        features=features.drop(['res name|'],axis=1)\n",
    "        letters = [letterabbreviation[base] for base in letters]\n",
    "        v=''.join(letters)\n",
    "        v=pd.DataFrame(letters,columns=['res name|'])\n",
    "        feat=pd.merge(v,features,right_index=True,left_index=True)\n",
    "        all_features.append(feat)\n",
    "        print(feat)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:34:21.178362Z",
     "start_time": "2021-09-01T05:34:19.608561Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features=mergeallfeatures(physical_features,chemical_features,pssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:34:36.225952Z",
     "start_time": "2021-09-01T05:34:23.671848Z"
    }
   },
   "outputs": [],
   "source": [
    "# simulating the interaction process between each cinsecutive two proteins\n",
    "receptor_ligand=[]\n",
    "for i in range(0,len(all_features),2):\n",
    "    ligand=all_features[i]\n",
    "    receptor=all_features[i+1]\n",
    "    ligandlenght=len(ligand)\n",
    "    r=receptor.loc[receptor.index.repeat(ligandlenght)].reset_index(drop=True)\n",
    "    receptorlenght=len(receptor)\n",
    "    l= pd.concat([ligand]*receptorlenght, ignore_index=True)\n",
    "    df=pd.merge(r,l,left_index=True,right_index=True)\n",
    "    print(df)\n",
    "    receptor_ligand.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(receptor_ligand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:34:38.892844Z",
     "start_time": "2021-09-01T05:34:36.226947Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "label_directory = os.listdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\negative and positive samples\")\n",
    "os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\negative and positive samples\")\n",
    "label=[]\n",
    "labelname=[]\n",
    "for file in range(0,len(label_directory)) :\n",
    "    os.chdir(r\"C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\negative and positive samples\")\n",
    "    samples=pd.read_csv(label_directory[file])\n",
    "    label.append(samples)\n",
    "    labelname.append(label_directory[file])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# each protien has a structure before interaction (where features are extracted) that is different that it's structure after interaction (where label or target is extracted using global alignment we were able to find the common strucutre between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:33:19.626212Z",
     "start_time": "2021-09-01T05:33:19.611251Z"
    }
   },
   "outputs": [],
   "source": [
    "def GET_SCORE(n1, n2, penalty = -1, reward = 1):\n",
    "     \n",
    "    if n1 == n2:\n",
    "        return reward\n",
    "    else:\n",
    "        return penalty\n",
    " \n",
    " \n",
    "def global_alignment(X, Y, penalty = -1, reward = 1):\n",
    "     \n",
    "    # initialize score matrix\n",
    "    score_matrix = np.ndarray((len(X) + 1, len(Y) + 1))\n",
    "      \n",
    "    for i in range(len(X) + 1):\n",
    "        score_matrix[i, 0] = penalty * i\n",
    "     \n",
    "    for j in range(len(Y) + 1):\n",
    "        score_matrix[0, j] = penalty * j\n",
    "         \n",
    "     \n",
    "    # define each cell in the matrix by as the max score possible in that stage\n",
    "    for i in range(1, len(X) + 1):\n",
    "        for j in range(1, len(Y) + 1):\n",
    "            match = score_matrix[i - 1, j - 1] + GET_SCORE(X[i - 1], Y[j - 1], penalty, reward)\n",
    "            delete = score_matrix[i -1, j] + penalty\n",
    "            insert = score_matrix[i, j - 1] + penalty\n",
    "             \n",
    "            score_matrix[i, j] = max([match, delete, insert])\n",
    "             \n",
    "     \n",
    "    i = len(X)\n",
    "    j = len(Y)\n",
    "     \n",
    "    global_alignment.align_X = \"\"\n",
    "    global_alignment.align_Y = \"\"\n",
    "     \n",
    "    while i > 0 or j > 0:\n",
    "         \n",
    "        current_score = score_matrix[i, j]\n",
    "        left_score = score_matrix[i - 1, j]\n",
    "         \n",
    "         \n",
    "        if i > 0 and j > 0 and X[i - 1] == Y[j - 1]:\n",
    "            global_alignment.align_X = X[i - 1] + global_alignment.align_X\n",
    "            global_alignment.align_Y = Y[j - 1] + global_alignment.align_Y\n",
    "            i = i - 1\n",
    "            j = j - 1\n",
    "         \n",
    "        elif i > 0 and current_score == left_score + penalty:\n",
    "            global_alignment.align_X = X[i - 1] + global_alignment.align_X\n",
    "            global_alignment.align_Y = '*' + global_alignment.align_Y\n",
    "            i = i - 1\n",
    "             \n",
    "        else:\n",
    "            global_alignment.align_X = '*' + global_alignment.align_X\n",
    "            global_alignment.align_Y = Y[j - 1] + global_alignment.align_Y\n",
    "            j = j - 1\n",
    " \n",
    " \n",
    "    return global_alignment.align_X, global_alignment.align_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:37:13.671389Z",
     "start_time": "2021-09-01T05:37:13.643088Z"
    }
   },
   "outputs": [],
   "source": [
    "def disorder_removing(label,receptor_ligand):\n",
    "    disorderremoved=[]\n",
    "    for i in range(0,len(label)):\n",
    "        print(labelname[i])\n",
    "\n",
    "        feature=receptor_ligand[i]\n",
    "        sample=label[i]\n",
    "        df1=feature\n",
    "        z=df1['res id|_y']\n",
    "        f=1\n",
    "        for i in range(len(z)-1):\n",
    "            if z[i]<z[i+1]:\n",
    "                f+=1\n",
    "        \n",
    "            else:\n",
    "                break\n",
    "        s=df1['res name|_y'][:f]\n",
    "        a = list(s)\n",
    "        x = ''.join(str(e) for e in a)\n",
    "    #print(x)\n",
    "        df=sample\n",
    "        d=df['structResIdL']\n",
    "        q=1\n",
    "        for i in range(len(d)-1):\n",
    "            if d[i]<d[i+1]:\n",
    "                q+=1\n",
    "        \n",
    "            else:\n",
    "                break\n",
    "        m=df['resNameL'][:q]\n",
    "        a = list(m)\n",
    "        y = ''.join(str(e) for e in a)\n",
    "    #print(y)\n",
    "        global_alignment(x, y)\n",
    "        ax=global_alignment.align_X\n",
    "        ay=global_alignment.align_Y\n",
    "        print(ax)\n",
    "        print(ay)\n",
    "        colum=\" \".join(ax)\n",
    "        colum=colum.split()\n",
    "        colum1=\" \".join(ay)\n",
    "        colum1=colum1.split()\n",
    "        dfax = DataFrame (colum,columns=['alignmx'])\n",
    "        d1=df1['res id|_x']\n",
    "        c=1\n",
    "        for d in range(len(d1)-1):\n",
    "    \n",
    "            if d1[d]!=d1[d+1]:\n",
    "                c+=1\n",
    "        df_repeated = pd.concat([dfax]*c, ignore_index=True)\n",
    "    #print(df_repeated)\n",
    "        v=df_repeated.index[df_repeated['alignmx'] == '*'].tolist()\n",
    "        h=0\n",
    "        dfa=np.array(df1)\n",
    "        cols=df1.columns\n",
    "\n",
    "        l=[]\n",
    "        for i in v:\n",
    "            if i<=len(dfa):\n",
    "            \n",
    "                dfa=np.insert(dfa,i,\"nan\",axis = 0)\n",
    "  \n",
    "        if v:\n",
    "            \n",
    "            lu=pd.DataFrame(dfa,columns=cols)\n",
    "        else :\n",
    "            lu=pd.DataFrame(df1,columns=cols)\n",
    "        lu['alignmx']=df_repeated\n",
    "        #lu=pd.DataFrame(df_repeated,columns=cols)\n",
    "        \n",
    "        dfay1 = DataFrame(colum1,columns=['alignmy'])\n",
    "        df_repeated = pd.concat([dfay1]*c, ignore_index=True)\n",
    "        lu[\"aligny\"]=df_repeated\n",
    "        print(lu)\n",
    "        lu['Match'] = np.where(lu['aligny'] == \"*\", 'True', 'False') \n",
    "        index_names = lu[lu['Match'] ==\"True\"].index\n",
    "        lu.drop(index_names, inplace = True)\n",
    "        lu['Match'] = np.where(lu == \"nan\", 'True', 'False') \n",
    "        index_names = lu[lu['Match'] ==\"True\"].index\n",
    "        lu.drop(index_names, inplace = True)\n",
    "\n",
    "        df_repeated = pd.concat([dfay1]*c, ignore_index=True)\n",
    "    #print(df_repeated)\n",
    "        v=df_repeated.index[df_repeated['alignmy'] == '*'].tolist()\n",
    "        w=0\n",
    "        dfa=np.array(df)\n",
    "        for i in v:\n",
    "            if i<=len(dfa):\n",
    "                dfa=np.insert(dfa,i,\"nan\",axis = 0)\n",
    "    #x=np.insert(dfa,l,'nan',axis=0)\n",
    "\n",
    "        cols=df.columns\n",
    "        if v:\n",
    "        \n",
    "            lb=pd.DataFrame(dfa,columns=cols)\n",
    "        else:\n",
    "            lb=df\n",
    "        lb['alignmy']=df_repeated\n",
    "        lb=lb.dropna(axis=0)\n",
    "        df_repeated = pd.concat([dfax]*c, ignore_index=True)\n",
    "        lb['alignmx']=df_repeated\n",
    "        lb['Match'] = np.where(lb['alignmx'] == \"*\", 'True', 'False') \n",
    "        index_names = lb[lb['Match'] ==\"True\"].index\n",
    "        lb.drop(index_names, inplace = True)\n",
    "        lb=lb.dropna(axis=0)\n",
    "        index_names = lb[lb['Match'] ==\"True\"].index\n",
    "        lb.drop(index_names, inplace = True)\n",
    "        lb['Match'] = np.where(lb == 'nan', 'True', 'False')\n",
    "        index_names = lb[lb['Match'] ==\"True\"].index\n",
    "        lb.drop(index_names, inplace = True)\n",
    "        df3 = pd.merge(lu, lb, left_index=True, right_index=True)\n",
    "    #print(df3)\n",
    "        df=lu\n",
    "        df1=lb\n",
    "        m=df['res name|_x']\n",
    "        a = list(m)\n",
    "        x = ''.join(str(e) for e in a)\n",
    "\n",
    "        g=df1['resNameR']\n",
    "        a = list(g)\n",
    "        y = ''.join(str(e) for e in a)\n",
    "        df1.reset_index(inplace = True)\n",
    "\n",
    "        d1=df1['structResIdR']\n",
    "        li=[]\n",
    "        for i in range(len(d1)-1):\n",
    "    \n",
    "             if d1[i]!=d1[i+1]:\n",
    "                li.append(a[i])\n",
    "        li.append(a[-1])\n",
    "        ah= ''.join(str(e) for e in li)\n",
    "        df.reset_index(inplace = True)\n",
    "        d1=df['res id|_x']\n",
    "        li=[]\n",
    "        for i in range(len(d1)-1):\n",
    "    \n",
    "             if d1[i]!=d1[i+1]:\n",
    "                li.append(x[i])\n",
    "        li.append(x[-1])\n",
    "        x = ''.join(str(e) for e in li)\n",
    "        global_alignment(x,ah)\n",
    "        ax=global_alignment.align_X\n",
    "        ay=global_alignment.align_Y\n",
    "        print(ax)\n",
    "        print(ay)\n",
    "        colum=\" \".join(ax)\n",
    "        colum=colum.split()\n",
    "        colum1=\" \".join(ay)\n",
    "        colum1=colum1.split()\n",
    "        dfax = DataFrame (colum,columns=['alignmx'])\n",
    "        alignmx=dfax.loc[dfax.index.repeat(f)].reset_index(drop=True)\n",
    "        v=alignmx.index[alignmx['alignmx'] == '*'].tolist()\n",
    "        h=0\n",
    "        dfa=np.array(df1)\n",
    "        l=[]\n",
    "\n",
    "    #print(v)\n",
    "        for i in v:\n",
    "            if i<=len(dfa):\n",
    "                dfa=np.insert(dfa,i,\"nan\",axis = 0)\n",
    "    #x=np.insert(dfa,l,'nan',axis=0)\n",
    "      \n",
    "   # x=np.insert(dfa,v,'nan',axis=0)\n",
    "        cols=df1.columns\n",
    "        if v:\n",
    "            ru=pd.DataFrame(dfa,columns=cols)\n",
    "        else:\n",
    "            ru=df1\n",
    "        dfay1 = DataFrame(colum1,columns=['alignmy'])\n",
    "        alignmy=dfay1.loc[dfay1.index.repeat(f)].reset_index(drop=True)\n",
    "        print(alignmy)\n",
    "        v=alignmx.index[alignmx['alignmx'] == '*'].tolist()\n",
    "        h=0\n",
    "        dfa=np.array(df)\n",
    "\n",
    "        for i in v:\n",
    "            if i<=len(dfa):\n",
    "            \n",
    "                dfa=np.insert(dfa,i,\"nan\",axis = 0)\n",
    "        \n",
    "    \n",
    "    #x=np.insert(dfa,v,'nan',axis=0)\n",
    "        cols=df.columns\n",
    "        if v:\n",
    "            ru=pd.DataFrame(dfa,columns=cols)\n",
    "        else :\n",
    "            ru=df\n",
    "        ru['alignmx']=alignmx\n",
    "        ru[\"alignmy\"]=alignmy\n",
    "        ru['Match'] = np.where(ru['alignmy'] == \"*\", 'True', 'False') \n",
    "        index_names = ru[ru['Match'] ==\"True\"].index\n",
    "        ru.drop(index_names, inplace = True)\n",
    "        ru['Match'] = np.where(ru == \"nan\", 'True', 'False') \n",
    "        index_names = ru[ru['Match'] ==\"True\"].index\n",
    "        ru.drop(index_names, inplace = True)\n",
    "        v=alignmy.index[alignmy['alignmy'] == '*'].tolist()\n",
    "        h=0\n",
    "        dfa=np.array(df1)\n",
    "\n",
    "        for i in v:\n",
    "            if i<=len(dfa):\n",
    "            \n",
    "                dfa=np.insert(dfa,i,\"nan\",axis = 0)\n",
    "            \n",
    "    #x=np.insert(dfa,l,'nan',axis=0)\n",
    "\n",
    "    #x=np.insert(dfa,v,'nan',axis=0)\n",
    "        cols=df1.columns\n",
    "        if v:\n",
    "            rb=pd.DataFrame(dfa,columns=cols)\n",
    "        else:\n",
    "            rb=df1\n",
    "        rb['alignmy']=alignmy\n",
    "        rb['alignmx']=alignmx\n",
    "        rb['Match'] = np.where(rb['alignmx'] == \"*\", 'True', 'False') \n",
    "        index_names = rb[rb['Match'] ==\"True\"].index\n",
    "        rb.drop(index_names, inplace = True)\n",
    "        rb['Match'] = np.where(rb== 'nan', 'True', 'False') \n",
    "        index_names = rb[rb['Match'] ==\"True\"].index\n",
    "        rb.drop(index_names, inplace = True)\n",
    "        ru.reset_index(inplace=True)\n",
    "        rb.reset_index(inplace=True)\n",
    "        df3 = pd.merge(ru, rb, left_index=True, right_index=True)\n",
    "        df3.dropna(axis=0,inplace=True)\n",
    "\n",
    "        disorderremoved.append(df3)\n",
    "    return disorderremoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T05:37:42.433218Z",
     "start_time": "2021-09-01T05:37:15.886260Z"
    }
   },
   "outputs": [],
   "source": [
    "removed=disorder_removing(label,receptor_ligand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(r'C:\\Users\\ahmed hatem\\Downloads\\GP\\disorder removed')\n",
    "#for i in range(len(disorderremoved)):\n",
    "    #os.chdir(r'C:\\Users\\ahmed hatem\\Downloads\\GP\\disorder removed')\n",
    "\n",
    "    #disorderremoved[i].to_csv(labelname[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readyforundersampling=[]\n",
    "for i in range(0,len(temp)):\n",
    "    \n",
    "    protein=temp[i]\n",
    "    \n",
    "    protein.dropna(axis=0,inplace=True)\n",
    "\n",
    "    \n",
    "    protein=protein.drop(['index_x', 'level_0_x','level_0_y','res id|_x','res id|_y','chain id|_x','chain id|_y','alignmx_x', 'aligny', 'Match_x',\n",
    "       'alignmy_x',  'chainIdL', 'structResIdL',\n",
    "       'resNameL', 'chainIdR', 'structResIdR', 'resNameR','alignmx_y', 'Match_y','alignmy_y'],axis=1)\n",
    "    print(protein)\n",
    "    readyforundersampling.append(protein)\n",
    "readyforundersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(readyforundersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T13:48:38.019437Z",
     "start_time": "2021-08-30T13:47:56.473343Z"
    }
   },
   "outputs": [],
   "source": [
    "readyforundersampling=[]\n",
    "di=os.listdir(r'C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\disorder removed')\n",
    "os.chdir(r'C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\disorder removed')\n",
    "for i in range(len(di)):\n",
    "    os.chdir(r'C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\disorder removed')\n",
    "\n",
    "    df=pd.read_csv(di[i])\n",
    "    df=df.drop(['index_x', 'level_0_x','level_0_y','res id|_x','res id|_y','chain id|_x','chain id|_y','alignmx_x', 'aligny', 'Match_x',\n",
    "       'alignmy_x',  'chainIdL', 'structResIdL',\n",
    "       'resNameL', 'chainIdR', 'structResIdR', 'resNameR','alignmx_y', 'Match_y','alignmy_y','Unnamed: 0'],axis=1)\n",
    "\n",
    "    readyforundersampling.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T13:49:18.362006Z",
     "start_time": "2021-08-30T13:49:17.410587Z"
    }
   },
   "outputs": [],
   "source": [
    "readyforundersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T13:49:37.581193Z",
     "start_time": "2021-08-30T13:49:37.570235Z"
    }
   },
   "outputs": [],
   "source": [
    "def undersampling(readyforundersampling):\n",
    "    undersampleddata=[]\n",
    "    for a in range(len(readyforundersampling)):\n",
    "        #print(readyforundersampling)\n",
    "        protein=readyforundersampling[a]        \n",
    "        undersample = RandomUnderSampler()\n",
    "       # y_under=protein['prediction']\n",
    "        x = protein.iloc[:, 0 :170]\n",
    "        y = protein.iloc[:, [171]]\n",
    "        print(y)\n",
    "        z=y['prediction']\n",
    "        for v in range(len(z)):\n",
    "            if z[v]<0.6:\n",
    "                z[v]=0\n",
    "            else:\n",
    "                z[v]=1\n",
    "        z=z.astype('float')\n",
    "        x_under, y_under = undersample.fit_resample(x, z)\n",
    "    \n",
    "        #encoding={'A':10000000000000000000,'L':0o01000000000000000000,'I':0o00100000000000000000,'V':0o00010000000000000000,'G':0o00001000000000000000,'K':0o00000100000000000000,'R':0o00000010000000000000,'D':0o00000001000000000000,'E':0o00000000100000000000,'H':0o00000000010000000000,'N':0o00000000001000000000,'Q':0o00000000000100000000,'S':0o00000000000010000000,'T':0o00000000000001000000,'C':0o00000000000000100000,'M':0o00000000000000010000,'Y':0o00000000000000001000,'W':0o00000000000000000100,'F':0o00000000000000000010,'P':0o00000000000000000001}\n",
    "\n",
    "        #x_under['res name|_x'] = [encoding[base] for base in x_under['res name|_x']]\n",
    "        #x_under['res name|_y'] = [encoding[base] for base in x_under['res name|_y']]\n",
    "        #x_under=pd.DataFrame(x_under)\n",
    "        #y_under=pd.DataFrame(y_under)\n",
    "        undersampled=pd.merge(x_under,y_under,left_index=True,right_index=True)\n",
    "        undersampl=shuffle(undersampled)\n",
    "        #undersampl=undersampl.reset_index(inplace=True)\n",
    "\n",
    "        #print(undersampl )\n",
    "\n",
    "        undersampleddata.append(undersampl)\n",
    "    return undersampleddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T13:53:44.875795Z",
     "start_time": "2021-08-30T13:49:47.611579Z"
    }
   },
   "outputs": [],
   "source": [
    "undersampleddata=undersampling(readyforundersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(undersampleddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T13:55:58.067232Z",
     "start_time": "2021-08-30T13:55:37.309370Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\undersampled data_no-encoding')\n",
    "for i in range(len(undersampleddata)):\n",
    "    os.chdir(r'C:\\Users\\ahmed hatem\\Downloads\\Ahmed_Hatem20178003-mohamed khaled-20178056-mohamed-ali-20178036\\undersampled data_no-encoding')\n",
    "\n",
    "    undersampleddata[i].to_csv(labelname[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T13:54:14.529389Z",
     "start_time": "2021-08-30T13:54:14.511438Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(undersampleddata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T19:01:17.307636Z",
     "start_time": "2021-08-30T19:01:17.295674Z"
    }
   },
   "outputs": [],
   "source": [
    "pprint(undersampleddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-30T19:01:19.817547Z",
     "start_time": "2021-08-30T19:01:19.319853Z"
    }
   },
   "outputs": [],
   "source": [
    "print(undersampleddata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
